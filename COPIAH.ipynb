{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpET848XNI8IPVvAFV7oF8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoCarCampos/IME-USP-Python-Course/blob/main/COPIAH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J96dV21zing"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "def le_assinatura():\n",
        "    '''A funcao le os valores dos tracos linguisticos do modelo e devolve uma assinatura a ser comparada com os textos fornecidos'''\n",
        "    print(\"Bem-vindo ao detector automático de COH-PIAH.\")\n",
        "    print(\"Informe a assinatura típica de um aluno infectado:\")\n",
        "\n",
        "    wal = float(input(\"Entre o tamanho médio de palavra:\"))\n",
        "    ttr = float(input(\"Entre a relação Type-Token:\"))\n",
        "    hlr = float(input(\"Entre a Razão Hapax Legomana:\"))\n",
        "    sal = float(input(\"Entre o tamanho médio de sentença:\"))\n",
        "    sac = float(input(\"Entre a complexidade média da sentença:\"))\n",
        "    pal = float(input(\"Entre o tamanho medio de frase:\"))\n",
        "\n",
        "    return [wal, ttr, hlr, sal, sac, pal]\n",
        "\n",
        "def le_textos():\n",
        "    '''A funcao le todos os textos a serem comparados e devolve uma lista contendo cada texto como um elemento'''\n",
        "    i = 1\n",
        "    textos = []\n",
        "    texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\n",
        "    while texto:\n",
        "        textos.append(texto)\n",
        "        i += 1\n",
        "        texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\n",
        "\n",
        "    return textos\n",
        "\n",
        "def separa_sentencas(texto):\n",
        "    '''A funcao recebe um texto e devolve uma lista das sentencas dentro do texto'''\n",
        "    sentencas = re.split(r'[.!?]+', texto)\n",
        "    if sentencas[-1] == '':\n",
        "        del sentencas[-1]\n",
        "    return sentencas\n",
        "\n",
        "def separa_frases(sentenca):\n",
        "    '''A funcao recebe uma sentenca e devolve uma lista das frases dentro da sentenca'''\n",
        "    return re.split(r'[,:;]+', sentenca)\n",
        "\n",
        "def separa_palavras(frase):\n",
        "    '''A funcao recebe uma frase e devolve uma lista das palavras dentro da frase'''\n",
        "    return frase.split()\n",
        "\n",
        "def n_palavras_unicas(lista_palavras):\n",
        "    '''Essa funcao recebe uma lista de palavras e devolve o numero de palavras que aparecem uma unica vez'''\n",
        "    freq = dict()\n",
        "    unicas = 0\n",
        "    for palavra in lista_palavras:\n",
        "        p = palavra.lower()\n",
        "        if p in freq:\n",
        "            if freq[p] == 1:\n",
        "                unicas -= 1\n",
        "            freq[p] += 1\n",
        "        else:\n",
        "            freq[p] = 1\n",
        "            unicas += 1\n",
        "\n",
        "    return unicas\n",
        "\n",
        "def n_palavras_diferentes(lista_palavras):\n",
        "    '''Essa funcao recebe uma lista de palavras e devolve o numero de palavras diferentes utilizadas'''\n",
        "    freq = dict()\n",
        "    for palavra in lista_palavras:\n",
        "        p = palavra.lower()\n",
        "        if p in freq:\n",
        "            freq[p] += 1\n",
        "        else:\n",
        "            freq[p] = 1\n",
        "\n",
        "    return len(freq)\n",
        "\n",
        "\n",
        "def calcula_assinatura(texto):\n",
        "    ''' 1 - IMPLEMENTAR. Essa funcao recebe um texto e deve devolver a assinatura do texto.'''\n",
        "\n",
        "    wal = tamanho_medio_palavra(texto)\n",
        "    ttr = Type_Token(texto)\n",
        "    hlr = razao_hapax(texto)\n",
        "    sal = tamanho_medio_sentenca(texto)\n",
        "    sac = complexidade_sentenca(texto)\n",
        "    pal = tamanho_medio_frase(texto)\n",
        "\n",
        "    return [wal, ttr, hlr, sal, sac, pal]\n",
        "\n",
        "\n",
        "def compara_assinatura(as_a, as_b):\n",
        "    ''' 2 - IMPLEMENTAR. Essa funcao recebe duas assinaturas de texto e deve devolver o grau de similaridade nas assinaturas.'''\n",
        "    diferenca_total = sum(abs(as_a[i] - as_b[i]) for i in range(len(as_a)))\n",
        "\n",
        "    # Divide a soma das diferenças pelo número de traços (6)\n",
        "    grau_similaridade = diferenca_total / 6\n",
        "\n",
        "    return grau_similaridade\n",
        "\n",
        "\n",
        "def avalia_textos(textos, ass_cp):\n",
        "    ''' 3 - IMPLEMENTAR. Essa funcao recebe uma lista de textos e uma assinatura ass_cp e deve devolver o numero (1 a n) do texto com maior probabilidade de ter sido infectado por COH-PIAH.'''\n",
        "    assinaturas = [calcula_assinatura(texto) for texto in textos]\n",
        "    diferencas = [compara_assinatura(assinatura, ass_cp) for assinatura in assinaturas]\n",
        "\n",
        "    indice_menor_diferenca = diferencas.index(min(diferencas)) + 1  # +1 porque os índices começam em 1\n",
        "\n",
        "    return indice_menor_diferenca\n",
        "\n",
        "\n",
        "'fazer função Tamanho_medio_palavra'\n",
        "def tamanho_medio_palavra(frase):\n",
        "    # Divide a frase em palavras usando espaço como delimitador\n",
        "    palavras = frase.split()\n",
        "\n",
        "    # Se não houver palavras, a média é 0 para evitar divisão por zero\n",
        "    if not palavras:\n",
        "        return 0\n",
        "\n",
        "    # Calcula o total de caracteres e o número total de palavras\n",
        "    total_caracteres = sum(len(palavra) for palavra in palavras)\n",
        "    numero_palavras = len(palavras)\n",
        "\n",
        "    #Calcula a média de caracteres por palavra\n",
        "    media_caracteres = total_caracteres / numero_palavras\n",
        "    return round(media_caracteres, 2)\n",
        "\n",
        "\n",
        "'fazer função Relação Type-Token'\n",
        "def Type_Token(frase):\n",
        "    # Divide a frase em palavras usando espaço como delimitador\n",
        "    palavras = frase.split()\n",
        "\n",
        "    # Cria um conjunto para armazenar palavras únicas\n",
        "    palavras_unicas = set(palavras)\n",
        "\n",
        "    # Se n]ao houver palavras únicas, a média é 0 para evitar divisão por zero\n",
        "    if not palavras_unicas:\n",
        "        return 0\n",
        "\n",
        "    # Calcula o total de caracteres e o número total de palavras únicas\n",
        "    total_caracteres = sum(len(palavra) for palavra in palavras_unicas)\n",
        "    numero_palavras_unicas = len(palavras_unicas)\n",
        "\n",
        "    # Calcula a relação type-token\n",
        "    type_token = numero_palavras_unicas / total_caracteres\n",
        "\n",
        "    return round(type_token, 2)\n",
        "\n",
        "\n",
        "'fazer função Razão Hapax'\n",
        "def razao_hapax(frase):\n",
        "    # Divide a frase em palavras usando espaço como delimitador\n",
        "    palavras = frase.split()\n",
        "\n",
        "    # Cria um dicionário para armazenar a frequência de cada palavra\n",
        "    frequencia_palavras = {}\n",
        "    for palavra in palavras:\n",
        "        frequencia_palavras[palavra] = frequencia_palavras.get(palavra, 0) + 1\n",
        "    # Filtra palavras que aparecem apenas uma vez\n",
        "    palavras_unicas = [palavra for palavra, frequencia in frequencia_palavras.items() if frequencia ==1]\n",
        "\n",
        "    # Calcula a razão de palavra única sobre o total de palavras\n",
        "    razao_hapax = len(palavras_unicas) / len(palavras)\n",
        "\n",
        "    return round(razao_hapax, 2)\n",
        "\n",
        "'fazer função tamanho médio da sentença'\n",
        "def tamanho_medio_sentenca(frase):\n",
        "    # Divide a frase em sentenças usando pontuações como delimitadores\n",
        "    sentencas = [sentenca.strip() for sentenca in re.split(r'[.!?]', frase) if sentenca.strip()]\n",
        "\n",
        "    # Calcula o total de caracteres em todas as sentenças e o número de sentenças\n",
        "    total_caracteres_sentencas = sum(len(sentenca) for sentenca in sentencas)\n",
        "    numero_sentencas = len(sentencas)\n",
        "\n",
        "    # Calcula o tamanho médio de sentença\n",
        "    if numero_sentencas > 0:\n",
        "        tamanho_medio = total_caracteres_sentencas / numero_sentencas\n",
        "        return round(tamanho_medio, 2)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "'fazer função complexidade da sentença'\n",
        "def complexidade_sentenca(frase):\n",
        "    # Divide a frase em sentenças usando pontuações como delimitadores\n",
        "    sentencas = [sentenca.strip() for sentenca in re.split(r'[.!?]', frase) if sentenca.strip()]\n",
        "\n",
        "    # Calcula o número total de frases e o número de sentenças\n",
        "    numero_total_frases = sum(sentenca.count('.') + sentenca.count(',') + sentenca.count(':') + sentenca.count('!') + sentenca.count('?') for sentenca in sentencas)\n",
        "    numero_sentencas = len(sentencas)\n",
        "\n",
        "    # Calcula a complexidade da sentença\n",
        "    if numero_sentencas > 0:\n",
        "        complexidade = numero_total_frases / numero_sentencas\n",
        "        return round(complexidade, 2)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def tamanho_medio_frase(frase):\n",
        "    # Divide a frase em sentenças usando pontuações como delimitadores\n",
        "    sentencas = [sentenca.strip() for sentenca in re.split(r'[.!?,:]', frase) if sentenca.strip()]\n",
        "\n",
        "    # Calcula o número total de caracteres em todas as sentenças e o número total de frases\n",
        "    total_caracteres_sentencas = sum(len(sentenca) for sentenca in sentencas)\n",
        "    numero_total_frases = len(sentencas)\n",
        "\n",
        "    # Calcula o tamanho médio de frase\n",
        "    if numero_total_frases > 0:\n",
        "        tamanho_medio = total_caracteres_sentencas / numero_total_frases\n",
        "        return round(tamanho_medio, 2)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calcular_diferenca(tracos_a, tracos_b):\n",
        "    soma_diferencas = sum(abs(traco_a - traco_b) for traco_a, traco_b in zip(tracos_a, tracos_b))\n",
        "    return soma_diferencas\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    assinatura = le_assinatura()\n",
        "    textos = le_textos()\n",
        "    resultado = avalia_textos(textos, assinatura)\n",
        "    print(f\"O texto com maior probabilidade de ser COH-PIAH é o texto {resultado}.\")\n"
      ]
    }
  ]
}